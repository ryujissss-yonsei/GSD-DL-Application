{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e98ef146",
   "metadata": {},
   "source": [
    "# Libirary import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" os \"\"\"\n",
    "import os\n",
    "\n",
    "\"\"\" torch \"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Compose, Resize, ToTensor\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch import Tensor\n",
    "\n",
    "\"\"\"glob\"\"\"\n",
    "from glob import glob\n",
    "\n",
    "\"\"\" tqdm \"\"\"\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"Pandas\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\" numpy \"\"\"\n",
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from PIL import Image\n",
    "\n",
    "\"\"\"JSON\"\"\"\n",
    "import json\n",
    "\n",
    "\"\"\"sklearn\"\"\"\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "\"\"\"seaborn\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "\"\"\"scipy\"\"\"\n",
    "from scipy import io\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, ifft,fftfreq\n",
    "from scipy import stats\n",
    "\n",
    "\"\"\"time\"\"\"\n",
    "import time\n",
    "\n",
    "\"\"\"PIL\"\"\"\n",
    "from PIL import Image\n",
    "\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "import imageio\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2e1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8352fa1c",
   "metadata": {},
   "source": [
    "# Path init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07935912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "sys.path.append('/Function')\n",
    "from preprocessing import get_x_y_pairs, preprocessing \n",
    "from Train_classification import Model_Train, Model_Test,Model_Test_Youden_Index, T_SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6694a22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "work_path = \"\" # Our data paths, it is not opened\n",
    "os.chdir(work_path)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27942ba",
   "metadata": {},
   "source": [
    "# Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f993c",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    #init\n",
    "    \"Task\"              :\"Time series classification\",\n",
    "    \"Dataset\"           :\"GSD patients data\", \n",
    "    \"Patient\"           :'more then 14 days patients',\n",
    "    \"Data_Balanced\"     :\"Unknown\",\n",
    "    \"Filtering\"         :\"None\",\n",
    "    \"Normalization\"     :\"RobustScaler\",\n",
    "    \"Loss\"              :\"BCE loss\",\n",
    "    \"Preprocess\"        :\"\",\n",
    "    \"Model_name\"        :\"Patch TST\",\n",
    "    \"Hypo_threshold\"    :\"80\",\n",
    "    \"basic_path\"        :\"\", # result save path\n",
    "    \n",
    "    #hyper parameters\n",
    "    \"seed\"              :1,\n",
    "    \"lr\"                :0.001,\n",
    "    \"batch_size\"        :128, # 4096\n",
    "    \"test_batch_size\"   :1,\n",
    "    \"window_size\"       :48, # 12 hours\n",
    "    \"forcast_size\"      :4, # 1 hour\n",
    "    \"epochs\"            :100,\n",
    "    \"no_cuda\"           :False,\n",
    "    \"log_interval\"      :100,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274b19c5",
   "metadata": {},
   "source": [
    "# Set the seed and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092295df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "\n",
    "kwargs = {'num_workers':0,'pin_memory':True} if use_cuda else {}\n",
    "\n",
    "!nvcc --version\n",
    "#https://pytorch.org/get-started/previous-versions/\n",
    "print('--------------------------------------')\n",
    "print('현재 torch 버전:',torch.__version__)\n",
    "print('학습을 진행하는 기기:',device)\n",
    "print('cuda index:', torch.cuda.current_device())\n",
    "print('gpu 개수:', torch.cuda.device_count())\n",
    "print('graphic name:', torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edbbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d72558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ace31d",
   "metadata": {},
   "source": [
    "# Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Model')\n",
    "from N_Linear import LTSF_NLinear\n",
    "from D_Linear import LTSF_DLinear\n",
    "from TSMixer import TSMixer\n",
    "from PatchTST import PatchTST\n",
    "\n",
    "from Model_performance import model_performance_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad06002",
   "metadata": {},
   "source": [
    "# 1. TS Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbacaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(256, args.window_size, 7) \n",
    "target = torch.randn(256, args.forcast_size, 7)\n",
    "\n",
    "model = TSMixer(sequence_length=args.window_size, prediction_length=1, input_channels=7, output_channels=7, num_blocks=8)\n",
    "\n",
    "output = model(input) \n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd897363",
   "metadata": {},
   "source": [
    "# 2. M Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(256, args.window_size, 7) \n",
    "target = torch.randn(256, args.forcast_size, 7)\n",
    "\n",
    "model = LTSF_NLinear(window_size=args.window_size, forcast_size=1, individual=False, feature_size=7)\n",
    "\n",
    "output = model(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3b622",
   "metadata": {},
   "source": [
    "# 3. Patch TST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(256, args.window_size, 7) \n",
    "target = torch.randn(256, args.forcast_size, 7)\n",
    "\n",
    "model = PatchTST(channel = 7, window_size=args.window_size, forcast_size=1)\n",
    "\n",
    "output = model(input) \n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abd407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46502824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6dd04ae",
   "metadata": {},
   "source": [
    "# Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classification_model(nn.Module):\n",
    "    \n",
    "    def __init__(self, oup:int=7, class_n:int=1):\n",
    "        super(Classification_model,self).__init__()\n",
    "        \n",
    "        #self.TS_model = TSMixer(sequence_length=args.window_size, prediction_length=1, input_channels=7, output_channels=7, num_blocks=8)\n",
    "        #self.TS_model = LTSF_NLinear(window_size=args.window_size, forcast_size=1, individual=False, feature_size=7)\n",
    "        self.TS_model = PatchTST(channel = 7, window_size=args.window_size, forcast_size=1)\n",
    "        \n",
    "        \n",
    "        self.linear = nn.Linear(oup, class_n)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.TS_model(x) # B 1 7\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(256, args.window_size, 7) \n",
    "\n",
    "model = Classification_model()\n",
    "\n",
    "output = model(input) \n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf8831d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00b9ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea537ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e574f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e518137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de1da472",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5c704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_indexs, data_df, transform=None):\n",
    "        self.data_indexs = data_indexs\n",
    "        self.data_df     = data_df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        start = self.data_indexs[idx]\n",
    "        X  = self.data_df[start:start+args.window_size] # window\n",
    "        Y  = self.data_df[start+args.window_size:start+args.window_size+args.forcast_size] # forecast\n",
    "        \n",
    "        \n",
    "        \"\"\"data\"\"\"\n",
    "        year      = np.expand_dims(np.array(X['Year']),axis=1)\n",
    "        month     = np.expand_dims(np.array(X['Month']),axis=1)\n",
    "        day       = np.expand_dims(np.array(X['Day']),axis=1)\n",
    "        minutes   = np.expand_dims(np.array(X['Minutes']),axis=1)\n",
    "        min_sin   = np.expand_dims(np.array(X['Minutes_sin']),axis=1)\n",
    "        min_cos   = np.expand_dims(np.array(X['Minutes_cos']),axis=1)\n",
    "        \n",
    "\n",
    "        glu       = np.expand_dims(np.array(X['Glucose_level_original']),axis=1)\n",
    "        \n",
    "        data = np.concatenate((year, month, day, minutes, min_sin, min_cos, glu),axis=1)\n",
    "        \n",
    "        \n",
    "        \"\"\"get label\"\"\"\n",
    "        glu_original_y = np.array(Y['Glucose_level_original'])\n",
    "        \n",
    "        \n",
    "        #label = glu_original_y[0] # 15m\n",
    "        #label = glu_original_y[1] # 30m\n",
    "        #label = glu_original_y[2] # 45m\n",
    "        label = glu_original_y[3] # 60m\n",
    "        \n",
    "        if label <= float(args.Hypo_threshold):\n",
    "            label = int(1)\n",
    "        else:\n",
    "            label = int(0)\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_indexs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea04943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a741a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ceda3b0",
   "metadata": {},
   "source": [
    "# Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50d19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = os.listdir()\n",
    "data_paths\n",
    "len(data_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13ce4b",
   "metadata": {},
   "source": [
    "# Patients selection(more than 14 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63e42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_paths = []\n",
    "\n",
    "for i in range(0,len(data_paths),1):\n",
    "    data_path = data_paths[i]\n",
    "    df = pd.read_csv(data_path, engine='python', encoding='utf-8')\n",
    "    \n",
    "    day=np.round(len(df)/(4*24), 1)\n",
    "    if day < 14:\n",
    "        pass\n",
    "    else:\n",
    "        new_data_paths.append(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc683e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_data_paths)\n",
    "data_paths = new_data_paths\n",
    "len(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45066e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd063d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3c0fbe4",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_single_class(loader):\n",
    "    # Initialize a variable to track if only label 0 is found\n",
    "    only_zero_label = True\n",
    "\n",
    "    # Iterate over the DataLoader\n",
    "    for _, labels in loader:\n",
    "        # Check if there are any labels that are not 0\n",
    "        if torch.any(labels != 0):\n",
    "            only_zero_label = False\n",
    "            break\n",
    "\n",
    "    return only_zero_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59706e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_hypo = []\n",
    "\n",
    "for k in range(0,len(data_paths),1):\n",
    "    \n",
    "    \n",
    "    \"\"\"init\"\"\"\n",
    "    data_path           = data_paths[k]\n",
    "    args.experiment_num = k\n",
    "    df                  = pd.read_csv(data_path)\n",
    "    \n",
    "    \"\"\"make folder\"\"\"\n",
    "    result_save_path = args.basic_path + args.Model_name +'/'+str(args.experiment_num)\n",
    "\n",
    "    folder_path = result_save_path\n",
    "    try:\n",
    "        if not(os.path.isdir(folder_path)):\n",
    "            os.makedirs(os.path.join(folder_path))\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            print(\"Failed to create directory!!!!!\")\n",
    "            raise\n",
    "    args.fold_path = folder_path\n",
    "            \n",
    "            \n",
    "    \"\"\"---------------------------------------------Dataset split---------------------------------------------\"\"\"\n",
    "    train_df, valid_df, test_df = preprocessing(df, RobustScaler())\n",
    "    print(len(train_df), len(valid_df), len(test_df))\n",
    "    \n",
    "    \"\"\"---------------------------------------------Make pair---------------------------------------------\"\"\"\n",
    "    train_indexs   = get_x_y_pairs(train_df, args.window_size, args.forcast_size)\n",
    "    valid_indexs   = get_x_y_pairs(valid_df, args.window_size, args.forcast_size)\n",
    "    test_indexs    = get_x_y_pairs(test_df, args.window_size, args.forcast_size) # 전체 시간대\n",
    "\n",
    "    print(len(train_indexs),len(valid_indexs),len(test_indexs))\n",
    "    \n",
    "    \n",
    "    \"\"\"---------------------------------------------Custom dataset---------------------------------------------\"\"\"\n",
    "    train_dataset      = CustomDataset(train_indexs, train_df, transforms.Compose([transforms.ToTensor()]))\n",
    "    validation_dataset = CustomDataset(valid_indexs, valid_df, transforms.Compose([transforms.ToTensor()]))\n",
    "    test_dataset       = CustomDataset(test_indexs, test_df, transforms.Compose([transforms.ToTensor()])) # 전체 시간대\n",
    "    \n",
    "\n",
    "    print(len(train_dataset),len(validation_dataset), len(test_dataset))\n",
    "    \n",
    "    \"\"\"---------------------------------------------Data Loader---------------------------------------------\"\"\"\n",
    "    \"\"\"Train\"\"\"\n",
    "    args.train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size = args.batch_size,\n",
    "        shuffle = False, \n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    \"\"\"Validation\"\"\"\n",
    "    args.validation_loader = torch.utils.data.DataLoader(\n",
    "        dataset=validation_dataset,\n",
    "        batch_size = args.batch_size,\n",
    "        shuffle = False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    \"\"\"Test\"\"\"\n",
    "    args.test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size = args.test_batch_size,\n",
    "        shuffle = False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    print(\"Length of the train_loader:\", len(args.train_loader))\n",
    "    print(\"Length of the val_loader:\", len(args.validation_loader))\n",
    "    print(\"Length of the test_loader:\", len(args.test_loader))\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    \n",
    "    if check_single_class(args.validation_loader) == True:\n",
    "        no_hypo.append(k)\n",
    "        print(\"skipped, there is no hypo.\")\n",
    "        continue\n",
    "    elif check_single_class(args.test_loader) == True:\n",
    "        no_hypo.append(k)\n",
    "        print(\"skipped, there is no hypo.\")\n",
    "        continue\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    \"\"\"calculate pos_weight for unbalanced class\"\"\"\n",
    "    pos_class = 0\n",
    "    neg_class = 0\n",
    "    for batch_idx,(_,target) in enumerate(args.train_loader):\n",
    "        pos_class += len(target[np.where(target == 1)])\n",
    "        neg_class += len(target[np.where(target == 0)])\n",
    "        \n",
    "    pos_weight = torch.tensor([neg_class/pos_class], dtype = torch.float32)\n",
    "    \n",
    "    print(\"train 개수:\",len(train_indexs)) \n",
    "    print(\"num of class 1:\",pos_class) \n",
    "    print(\"num of class 0:\",neg_class)\n",
    "    print(pos_weight)\n",
    "    args.pos_weight = pos_weight\n",
    "    \n",
    "    \"\"\"---------------------------------------------optimizer---------------------------------------------\"\"\"\n",
    "    args.device = device\n",
    "    args.model = Classification_model().to(device)\n",
    "    args.optimizer = optim.Adam(args.model.parameters(), lr=args.lr)\n",
    "    args.criterion = nn.BCEWithLogitsLoss(pos_weight = args.pos_weight.cuda())\n",
    "    \n",
    "    \"\"\"Train\"\"\"\n",
    "    args.best_acc, args.best_auroc, args.best_epoch, avg_train_losses, avg_valid_losses, Train_ACC, Validation_ACC, Train_AUROC, Validation_AUROC = Model_Train(args)\n",
    "    \n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    loss_save_path = args.fold_path +'/Loss.png'\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(range(1,len(avg_train_losses)+1),avg_train_losses, label='Training Loss')\n",
    "    plt.plot(range(1,len(avg_valid_losses)+1),avg_valid_losses, label='Validation Loss')\n",
    "\n",
    "\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(loss_save_path, dpi = 200) \n",
    "    #plt.show()\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    acc_save_path = args.fold_path +'/Acc and AUROC.png'\n",
    "\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "    plt.plot (range(1,len(Train_ACC)+1),np.array(Train_ACC)/100, label='Train ACC',alpha = 0.2 )\n",
    "    plt.plot (range(1,len(Validation_ACC)+1),np.array(Validation_ACC)/100, label='Validation ACC',alpha = 0.2)\n",
    "    plt.plot (range(1,len(Train_AUROC)+1),np.array(Train_AUROC), label='Train AUROC')\n",
    "    plt.plot (range(1,len(Validation_AUROC)+1),np.array(Validation_AUROC), label='Validation AUROC')\n",
    "\n",
    "    plt.vlines(args.best_epoch,0.1,1.0,'r','--')\n",
    "    plt.text(args.best_epoch, 0.1,' best model',fontsize = 15)\n",
    "\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('acc and auroc')\n",
    "\n",
    "    plt.xlim(0, len(Train_ACC)+1)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc = 'lower right', fancybox = False, edgecolor = 'k', framealpha = 1.0,fontsize = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_save_path, dpi = 200) \n",
    "    #plt.show()\n",
    "    \n",
    "    plt.cla()\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    \n",
    "    args.test_result = Model_Test(args)\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    \n",
    "    args.test_result_youden_index = Model_Test_Youden_Index(args)\n",
    "    \n",
    "    print('----------------------------------------------------------------')\n",
    "    \n",
    "    \"\"\"save\"\"\"\n",
    "    args_copy = args.copy()\n",
    "    del_list = ['train_loader','validation_loader','test_loader','model','test_result', 'test_result_youden_index']\n",
    "\n",
    "    for i in range(len(del_list)):\n",
    "        del args_copy[del_list[i]]\n",
    "\n",
    "    df_train = pd.DataFrame(args_copy,index = [0]).T\n",
    "    df_train.to_excel(args.fold_path +'/Result.xlsx',index=True)\n",
    "    \n",
    "    df_test = pd.DataFrame(args.test_result,index = [0]).T\n",
    "    df_test.to_excel(args.fold_path +'/Result_test.xlsx',index=True)\n",
    "    \n",
    "    df_test_youden = pd.DataFrame(args.test_result_youden_index,index = [0]).T\n",
    "    df_test_youden.to_excel(args.fold_path +'/Result_test_youden.xlsx',index=True)\n",
    "    \n",
    "    \n",
    "    print(\"result was saved.\")\n",
    "    print('----------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a48610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c9fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27344c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8349518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
